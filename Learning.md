
| Flaky test | æœ‰æ—¶è¿‡ï¼Œæœ‰æ—¶ä¸è¿‡ |
| --- | --- |
| Mock | å¯éªŒè¯è¡Œä¸ºçš„å‡å¯¹è±¡ |
| Stub | åªè¿”å›æ•°æ®çš„å‡å¯¹è±¡ |
| Smoke test | å¿«é€Ÿçœ‹â€œè¿˜èƒ½ä¸èƒ½ç”¨â€ |
| Regression test | æ–°æ”¹åŠ¨æ²¡å¼„åæ—§åŠŸèƒ½ |
| Performance test | æ­£å¸¸è´Ÿè½½ä¸‹å¿«ä¸å¿« |
| Load test | é¢„æœŸæœ€å¤§ç”¨æˆ·ä¸‹ç¨³ä¸ç¨³ |
| Stress test | è¶…è´Ÿè½½ä¸‹ä»€ä¹ˆæ—¶å€™å´© |
| HIL | çœŸç¡¬ä»¶ + æ¨¡æ‹Ÿè½¯ä»¶ |

# **Flaky Testï¼ˆä¸ç¨³å®šæµ‹è¯•ï¼‰**

ğŸ‘‰ åŒä¸€ä»½ä»£ç ã€åŒä¸€ä¸ªæµ‹è¯•ï¼Œæœ‰æ—¶é€šè¿‡ï¼Œæœ‰æ—¶å¤±è´¥ã€‚

ä¸ºä»€ä¹ˆä¼šè¿™æ ·ï¼Ÿ

- ä¾èµ–æ—¶é—´ï¼ˆå¼‚æ­¥ã€å»¶è¿Ÿï¼‰
- ç½‘ç»œ / æ•°æ®åº“ä¸ç¨³å®š
- æµ‹è¯•ä¹‹é—´äº’ç›¸å½±å“
- å¤šçº¿ç¨‹ / å¹¶å‘é—®é¢˜

ä¾‹å­ï¼š

UI æµ‹è¯•é‡Œç­‰ 2 ç§’å†ç‚¹æŒ‰é’®ï¼Œæœ‰æ—¶é¡µé¢è¿˜æ²¡åŠ è½½å®Œå°±å¤±è´¥ã€‚

# **Mockï¼ˆæ¨¡æ‹Ÿå¯¹è±¡ï¼‰**

ğŸ‘‰ ç”¨å‡çš„å¯¹è±¡ï¼Œæ¥ä»£æ›¿çœŸå®ä¾èµ–ï¼Œåªæµ‹è¯•ä½ å…³å¿ƒçš„é€»è¾‘ã€‚

ç”¨æ¥å¹²å˜›ï¼Ÿ

- ä¸è®¿é—®çœŸå®æœåŠ¡å™¨
- ä¸ç”¨çœŸå®æ•°æ®åº“
- ä¸ä¾èµ–å¤–éƒ¨ç³»ç»Ÿ

ä¾‹å­ï¼š

æµ‹è¯•ç™»å½•é€»è¾‘æ—¶ï¼Œç”¨ mock API ç›´æ¥è¿”å›â€œç™»å½•æˆåŠŸâ€ã€‚

# **Hardware-in-the-Loopï¼ˆHILï¼Œç¡¬ä»¶åœ¨ç¯ï¼‰**

ğŸ‘‰ çœŸå®ç¡¬ä»¶ + æ¨¡æ‹Ÿçš„è½¯ä»¶ç¯å¢ƒä¸€èµ·æµ‹è¯•ã€‚

å¸¸è§åœºæ™¯ï¼š

- åµŒå…¥å¼ç³»ç»Ÿ
- æ±½è½¦ã€ä¼ æ„Ÿå™¨ã€åŒ»ç–—è®¾å¤‡

ä¾‹å­ï¼š

çœŸå®ä¼ æ„Ÿå™¨æ¥åœ¨æµ‹è¯•å°ä¸Šï¼Œä½†è¾“å…¥ä¿¡å·æ˜¯è½¯ä»¶æ¨¡æ‹Ÿçš„ã€‚

# **Smoke Testï¼ˆå†’çƒŸæµ‹è¯•ï¼‰**

ğŸ‘‰ å¿«é€Ÿç¡®è®¤ç³»ç»Ÿâ€œåŸºæœ¬è¿˜èƒ½ä¸èƒ½ç”¨â€ã€‚

ç‰¹ç‚¹ï¼š

- æµ‹å¾—æµ…
- æµ‹å¾—å¿«
- å¤±è´¥å°±ç›´æ¥åœæ­¢åç»­æµ‹è¯•

ä¾‹å­ï¼š

App èƒ½ä¸èƒ½å¯åŠ¨ï¼Ÿ

èƒ½ä¸èƒ½ç™»å½•ï¼Ÿ

ä¸»é¡µèƒ½ä¸èƒ½æ‰“å¼€ï¼Ÿ

# **Stubï¼ˆæ¡©ï¼‰**

ğŸ‘‰ è¿”å›å›ºå®šç»“æœçš„ç®€å•å‡å¯¹è±¡ã€‚

å’Œ Mock çš„åŒºåˆ«ï¼ˆé‡ç‚¹ï¼‰ï¼š

- Stubï¼šåªè´Ÿè´£â€œç»™æ•°æ®â€
- Mockï¼šè¿˜èƒ½éªŒè¯â€œæœ‰æ²¡æœ‰è¢«æ­£ç¡®è°ƒç”¨â€

ä¾‹å­ï¼š

ä¸€ä¸ª stub API æ°¸è¿œè¿”å›ï¼š

{ "status": "ok" }

# **Regression Testï¼ˆå›å½’æµ‹è¯•ï¼‰**

ğŸ‘‰ ç¡®è®¤æ–°æ”¹åŠ¨æ²¡æœ‰ç ´åæ—§åŠŸèƒ½ã€‚

ä»€ä¹ˆæ—¶å€™åšï¼Ÿ

- ä¿® bug å
- åŠ æ–°åŠŸèƒ½å
- é‡æ„å

ä¾‹å­ï¼š

åŠ äº†é¢„ç®—åŠŸèƒ½ â†’ å†æµ‹è¯•åŸæ¥çš„è®°è´¦ã€ç»Ÿè®¡åŠŸèƒ½ã€‚

# **Performance Testï¼ˆæ€§èƒ½æµ‹è¯•ï¼‰**

ğŸ‘‰ ç³»ç»Ÿåœ¨æ­£å¸¸è´Ÿè½½ä¸‹è·‘å¾—å¿«ä¸å¿«ã€ç¨³ä¸ç¨³ã€‚

å…³æ³¨ç‚¹ï¼š

- å“åº”æ—¶é—´
- ååé‡
- èµ„æºä½¿ç”¨ï¼ˆCPU / å†…å­˜ï¼‰

ä¾‹å­ï¼š

100 ä¸ªç”¨æˆ·åŒæ—¶ç”¨ Appï¼Œé¡µé¢æ‰“å¼€è¦å¤šä¹…ï¼Ÿ

# **Stress Testï¼ˆå‹åŠ›æµ‹è¯•ï¼‰**

ğŸ‘‰ æŠŠç³»ç»Ÿé€¼åˆ°æé™ï¼Œçœ‹å®ƒä»€ä¹ˆæ—¶å€™å´©ã€‚

ç›®çš„ï¼š

- æ‰¾ç³»ç»Ÿæœ€å¤§æ‰¿å—èƒ½åŠ›
- çœ‹å´©æºƒæ—¶æ˜¯å¦â€œä¼˜é›…å¤±è´¥â€

ä¾‹å­ï¼š

ä¸€ç›´å¢åŠ ç”¨æˆ·æ•°ï¼Œç›´åˆ°æœåŠ¡å™¨æŒ‚æ‰ã€‚

# **Load Testï¼ˆè´Ÿè½½æµ‹è¯•ï¼‰**

ğŸ‘‰ åœ¨â€œé¢„æœŸçš„æœ€å¤§ä½¿ç”¨é‡â€ä¸‹æµ‹è¯•ç³»ç»Ÿè¡¨ç°ã€‚

å’Œå‹åŠ›æµ‹è¯•çš„åŒºåˆ«ï¼š

- Load testï¼šæ­£å¸¸ä½†é«˜è´Ÿè½½
- Stress testï¼šè¶…å‡ºæ­£å¸¸èŒƒå›´

ä¾‹å­ï¼š

é¢„è®¡é«˜å³°æœŸ 1000 ç”¨æˆ· â†’ æµ‹ 1000 ç”¨æˆ·æ˜¯å¦è¿˜èƒ½ç¨³å®šè¿è¡Œã€‚


---
### Coverage meters

### a) Statement coverageï¼ˆè¯­å¥è¦†ç›–ï¼‰

https://www.geeksforgeeks.org/software-testing/statement-coverage-testing/

### b) Decision / Branch coverageï¼ˆåˆ¤å®š/åˆ†æ”¯è¦†ç›–ï¼‰

https://www.geeksforgeeks.org/software-engineering/what-is-branch-coverage-in-unit-testing/

### c) Condition coverageï¼ˆæ¡ä»¶è¦†ç›–ï¼‰

https://www.tutorialspoint.com/software_testing_dictionary/condition_coverage_testing.htm

### d) Multiple Condition Coverageï¼ˆMCCï¼Œå¤šæ¡ä»¶è¦†ç›–ï¼‰

https://www.qt.io/quality-assurance/coco/feature-multiple-condition-coverage-mcc

---

### ISTQB:s testing related vocabulary

1st term:Â AnÂ **anti-pattern**Â is like a bad habit that seems helpful at first but actually makes things worse. It's similar to always taking a shortcut through a neighborhood that has lots of stop signs - you think it's faster, but it actually takes longer than the main road. In software testing, this might be skipping documentation to "save time" but then causing confusion later when nobody remembers how the tests work.

2nd term:**Bebugging**Â is deliberately adding mistakes to your software to see if your testing can find them. It's like asking a friend to hide Easter eggs in your yard, and then seeing how many you can find - this helps you estimate how many eggs (or bugs) might still be hidden. For example, a team might intentionally add five calculation errors to their accounting software and then see if their testing process catches all five.

3rd term:**Beta testing**Â is when real users try your software before it's officially released. It's like a restaurant's "soft opening" where they invite people to dine before the grand opening to get feedback. For instance, when a game company lets selected players try a new game before its official launch to find problems and get suggestions for improvements.

4th term:AÂ **smoke test**Â quickly checks if the basic functions of software work before doing detailed testing. This is like turning on a new TV just to make sure it powers up and shows a picture before adjusting all the settings and connecting all your devices. For example, checking that a banking app lets you log in and view your balance (the most critical functions) before testing more complex features like setting up automatic payments.

### V-model and testing pyramid

**Understanding the V-Model**Â helps clarify the relationship between development and testing activities, verification and validation processes, and ensures appropriate test planning at each stage of development.

While the V-Model is typically associated with waterfall methodologies, theÂ **Testing Pyramid**Â is more common in agile approaches. The Testing Pyramid addresses efficiency by distributing test quantities across levels - numerous unit tests at the base, fewer integration tests in the middle, and minimal UI/system tests at the top.

**SUT (System Under Test)** æ˜¯æŒ‡æ­£åœ¨è¢«æµ‹è¯•çš„ç³»ç»Ÿã€‚åœ¨è½¯ä»¶æµ‹è¯•ä¸­,SUT æ˜¯ä½ è¦æ£€æŸ¥å’ŒéªŒè¯çš„ç›®æ ‡è½¯ä»¶ã€åº”ç”¨ç¨‹åºæˆ–ç³»ç»Ÿç»„ä»¶ã€‚ä¾‹å¦‚,å¦‚æœä½ æ­£åœ¨æµ‹è¯•ä¸€ä¸ªé“¶è¡Œåº”ç”¨ç¨‹åº,é‚£ä¹ˆè¿™ä¸ªé“¶è¡Œåº”ç”¨ç¨‹åºå°±æ˜¯ SUTã€‚æµ‹è¯•äººå‘˜ä¼šå¯¹ SUT æ‰§è¡Œå„ç§æµ‹è¯•ç”¨ä¾‹,ä»¥ç¡®ä¿å®ƒæŒ‰é¢„æœŸå·¥ä½œå¹¶æ‰¾å‡ºå¯èƒ½å­˜åœ¨çš„é”™è¯¯æˆ–é—®é¢˜ã€‚

### test cases and test case design

**Pair coverage testing** (ä¹Ÿç§°ä¸º pairwise testing æˆ– all-pairs testing) æ˜¯ä¸€ç§æµ‹è¯•æŠ€æœ¯,ç”¨äºæµ‹è¯•å…·æœ‰å¤šä¸ªè¾“å…¥å‚æ•°çš„ç³»ç»Ÿã€‚å®ƒçš„æ ¸å¿ƒæ€æƒ³æ˜¯:ä¸éœ€è¦æµ‹è¯•æ‰€æœ‰å‚æ•°çš„æ‰€æœ‰å¯èƒ½ç»„åˆ,åªéœ€è¦ç¡®ä¿ä»»æ„ä¸¤ä¸ªå‚æ•°çš„æ‰€æœ‰å¯èƒ½ç»„åˆéƒ½è‡³å°‘è¢«æµ‹è¯•ä¸€æ¬¡ã€‚

ä¾‹å¦‚,å‡è®¾ä¸€ä¸ªç™»å½•ç³»ç»Ÿæœ‰ä¸‰ä¸ªå‚æ•°:

- æµè§ˆå™¨ç±»å‹:Chromeã€Firefoxã€Safari(3ç§é€‰æ‹©)
- æ“ä½œç³»ç»Ÿ:Windowsã€Macã€Linux(3ç§é€‰æ‹©)
- è¯­è¨€:è‹±è¯­ã€ä¸­æ–‡ã€æ—¥è¯­(3ç§é€‰æ‹©)

å¦‚æœè¦æµ‹è¯•æ‰€æœ‰å¯èƒ½çš„ç»„åˆ,éœ€è¦ 3 Ã— 3 Ã— 3 = 27 ä¸ªæµ‹è¯•ç”¨ä¾‹ã€‚ä½†ä½¿ç”¨ pair coverage testing,åªéœ€è¦å¤§çº¦ 9 ä¸ªæµ‹è¯•ç”¨ä¾‹å°±å¯ä»¥ç¡®ä¿ä»»æ„ä¸¤ä¸ªå‚æ•°çš„æ‰€æœ‰ç»„åˆéƒ½è¢«è¦†ç›–åˆ°ã€‚

**ä¸ºä»€ä¹ˆå¤§çº¦åªéœ€è¦ 9 ä¸ªæµ‹è¯•ç”¨ä¾‹?**

è¿™æ˜¯å› ä¸º pair coverage testing ä½¿ç”¨äº†æ•°å­¦ä¼˜åŒ–ç®—æ³•æ¥ç”Ÿæˆæœ€å°çš„æµ‹è¯•ç”¨ä¾‹é›†ã€‚è®©æˆ‘ä»¬ç”¨ä¸Šé¢çš„ä¾‹å­æ¥è¯´æ˜:

**å‚æ•°:**

- æµè§ˆå™¨:Chrome (C)ã€Firefox (F)ã€Safari (S)
- æ“ä½œç³»ç»Ÿ:Windows (W)ã€Mac (M)ã€Linux (L)
- è¯­è¨€:è‹±è¯­ (E)ã€ä¸­æ–‡ (Z)ã€æ—¥è¯­ (J)

**å¯èƒ½çš„ 9 ä¸ªæµ‹è¯•ç”¨ä¾‹ç¤ºä¾‹:**

1. C + W + E
2. C + M + Z
3. C + L + J
4. F + W + Z
5. F + M + J
6. F + L + E
7. S + W + J
8. S + M + E
9. S + L + Z

é€šè¿‡è¿™ 9 ä¸ªæµ‹è¯•ç”¨ä¾‹,æˆ‘ä»¬ç¡®ä¿äº†:

- æµè§ˆå™¨å’Œæ“ä½œç³»ç»Ÿçš„æ‰€æœ‰ç»„åˆéƒ½è¢«æµ‹è¯•åˆ°(å¦‚ C+Wã€C+Mã€C+Lã€F+W ç­‰)
- æµè§ˆå™¨å’Œè¯­è¨€çš„æ‰€æœ‰ç»„åˆéƒ½è¢«æµ‹è¯•åˆ°(å¦‚ C+Eã€C+Zã€C+Jã€F+E ç­‰)
- æ“ä½œç³»ç»Ÿå’Œè¯­è¨€çš„æ‰€æœ‰ç»„åˆéƒ½è¢«æµ‹è¯•åˆ°(å¦‚ W+Eã€W+Zã€W+Jã€M+E ç­‰)

è¿™ç§æ–¹æ³•åˆ©ç”¨äº†**æ­£äº¤æ•°ç»„(Orthogonal Arrays)**æˆ–ç±»ä¼¼çš„ç»„åˆæ•°å­¦æŠ€æœ¯,ç¡®ä¿ç”¨æœ€å°‘çš„æµ‹è¯•ç”¨ä¾‹è¦†ç›–æ‰€æœ‰çš„ä¸¤ä¸¤å‚æ•°ç»„åˆã€‚å®é™…éœ€è¦çš„æµ‹è¯•ç”¨ä¾‹æ•°é‡å¯èƒ½åœ¨ 9-12 ä¸ªä¹‹é—´,å…·ä½“å–å†³äºä½¿ç”¨çš„ç®—æ³•å’Œå·¥å…·ã€‚

**ä¼˜ç‚¹:**

- å¤§å¹…å‡å°‘æµ‹è¯•ç”¨ä¾‹æ•°é‡,èŠ‚çœæ—¶é—´å’Œèµ„æº
- ç ”ç©¶è¡¨æ˜,å¤§å¤šæ•°è½¯ä»¶ç¼ºé™·æ˜¯ç”±å•ä¸ªå‚æ•°æˆ–ä¸¤ä¸ªå‚æ•°çš„äº¤äº’å¼•èµ·çš„,å› æ­¤è¿™ç§æ–¹æ³•èƒ½å‘ç°å¤§éƒ¨åˆ†é—®é¢˜
- æ¯”å®Œå…¨éšæœºæµ‹è¯•æ›´ç³»ç»Ÿå’Œå…¨é¢

**å±€é™æ€§:**

- æ— æ³•æ£€æµ‹éœ€è¦ä¸‰ä¸ªæˆ–æ›´å¤šå‚æ•°åŒæ—¶äº¤äº’æ‰ä¼šå‡ºç°çš„ç¼ºé™·
- å¯¹äºå‚æ•°é—´æœ‰å¤æ‚ä¾èµ–å…³ç³»çš„ç³»ç»Ÿå¯èƒ½ä¸å¤Ÿå……åˆ†

### equivalent classes

### exploratory testing

### dynamic testing

### risk analysis

### MoSCoW ä¼˜å…ˆçº§æ–¹æ³•

**MoSCoW** æ˜¯ä¸€ç§ç”¨äºè½¯ä»¶å¼€å‘å’Œé¡¹ç›®ç®¡ç†çš„ä¼˜å…ˆçº§æ’åºæ–¹æ³•,å¸®åŠ©å›¢é˜Ÿå†³å®šå“ªäº›åŠŸèƒ½æˆ–éœ€æ±‚æœ€é‡è¦ã€‚è¿™ä¸ªåç§°æ¥è‡ªå››ä¸ªä¼˜å…ˆçº§ç±»åˆ«çš„é¦–å­—æ¯:

- **M - Must have (å¿…é¡»æœ‰)**:è¿™äº›æ˜¯é¡¹ç›®æˆåŠŸçš„å…³é”®éœ€æ±‚,æ²¡æœ‰å®ƒä»¬é¡¹ç›®å°±æ— æ³•äº¤ä»˜ã€‚ä¾‹å¦‚,ä¸€ä¸ªé“¶è¡Œåº”ç”¨å¿…é¡»èƒ½å¤Ÿè®©ç”¨æˆ·ç™»å½•å’ŒæŸ¥çœ‹è´¦æˆ·ä½™é¢ã€‚
- **S - Should have (åº”è¯¥æœ‰)**:è¿™äº›éœ€æ±‚å¾ˆé‡è¦,ä½†ä¸æ˜¯ç»å¯¹å¿…éœ€çš„ã€‚å¦‚æœæ—¶é—´ä¸å¤Ÿ,å¯ä»¥æ¨è¿Ÿåˆ°ä¸‹ä¸€ä¸ªç‰ˆæœ¬ã€‚ä¾‹å¦‚,é“¶è¡Œåº”ç”¨åº”è¯¥æœ‰äº¤æ˜“å†å²ç­›é€‰åŠŸèƒ½,ä½†æ²¡æœ‰å®ƒä¹Ÿèƒ½åŸºæœ¬ä½¿ç”¨ã€‚
- **C - Could have (å¯ä»¥æœ‰)**:è¿™äº›æ˜¯"é”¦ä¸Šæ·»èŠ±"çš„åŠŸèƒ½,æœ‰äº†æ›´å¥½,ä½†ä¼˜å…ˆçº§æœ€ä½ã€‚ä¾‹å¦‚,è‡ªå®šä¹‰ä¸»é¢˜é¢œè‰²æˆ–ä¸ªæ€§åŒ–ç•Œé¢ã€‚
- **W - Won't have (æš‚ä¸éœ€è¦)**:è¿™äº›æ˜¯å›¢é˜Ÿæ˜ç¡®å†³å®šåœ¨å½“å‰ç‰ˆæœ¬ä¸­ä¸å®ç°çš„åŠŸèƒ½,å¯èƒ½ä¼šåœ¨æœªæ¥è€ƒè™‘ã€‚

**åœ¨æµ‹è¯•ä¸­çš„åº”ç”¨:**

MoSCoW æ–¹æ³•å¸®åŠ©æµ‹è¯•å›¢é˜Ÿç¡®å®šæµ‹è¯•ä¼˜å…ˆçº§ã€‚æµ‹è¯•äººå‘˜åº”è¯¥é¦–å…ˆä¸“æ³¨äºæµ‹è¯• "Must have" åŠŸèƒ½,ç¡®ä¿æ ¸å¿ƒåŠŸèƒ½æ­£å¸¸å·¥ä½œã€‚ç„¶åå†æµ‹è¯• "Should have" å’Œ "Could have" åŠŸèƒ½ã€‚è¿™æ ·å³ä½¿æ—¶é—´æœ‰é™,ä¹Ÿèƒ½ç¡®ä¿æœ€é‡è¦çš„åŠŸèƒ½å¾—åˆ°å……åˆ†æµ‹è¯•ã€‚

**ä¼˜ç‚¹:**

- å¸®åŠ©å›¢é˜Ÿåœ¨èµ„æºæœ‰é™æ—¶åšå‡ºæ˜æ™ºçš„å†³ç­–
- ç¡®ä¿å…³é”®åŠŸèƒ½å¾—åˆ°ä¼˜å…ˆå…³æ³¨
- ä¿ƒè¿›å›¢é˜Ÿå’Œåˆ©ç›Šç›¸å…³è€…ä¹‹é—´çš„æ¸…æ™°æ²Ÿé€š

**ç¤ºä¾‹åœºæ™¯:**

å‡è®¾ä½ æ­£åœ¨å¼€å‘ä¸€ä¸ªåœ¨çº¿è´­ç‰©ç½‘ç«™,ä½¿ç”¨ MoSCoW æ–¹æ³•å¯èƒ½ä¼šè¿™æ ·åˆ†ç±»:

- **Must have**:ç”¨æˆ·æ³¨å†Œã€ç™»å½•ã€æµè§ˆå•†å“ã€æ·»åŠ åˆ°è´­ç‰©è½¦ã€ç»“è´¦æ”¯ä»˜
- **Should have**:å•†å“è¯„ä»·ç³»ç»Ÿã€æ„¿æœ›æ¸…å•ã€è®¢å•è¿½è¸ª
- **Could have**:å•†å“æ¨èã€ç¤¾äº¤åª’ä½“åˆ†äº«ã€è™šæ‹Ÿè¯•ç©¿
- **Won't have** (æœ¬ç‰ˆæœ¬):è™šæ‹ŸåŠ©æ‰‹èŠå¤©åŠŸèƒ½ã€AR äº§å“é¢„è§ˆ

### four metres

1. **Amount of passing test cases**
    - **Useful info**: Shows how much of the system coders have tested and how stable it is.
    - **Bad behaviour**: Testers might write super easy tests just to get more passes.
2. **Defect fixing time**
    - **Useful info**: Shows how quickly coders fix bugs and how good they are at it.
    - **Bad behaviour**: Coders might rush fixes without proper testing, or testers might only report "easy-to-fix" bugs.
3. **Requirements coverage**
    - **Useful info**: Shows how much of what the customer wanted is actually tested.
    - **Bad behaviour**: Coders may only focus on things they can measure, ignoring stuff like "is it easy to use?" or "is it fast enough?"
4. **Test case efficiency**
    - **Useful info**: Tells if testers are writing tests that actually catch real problems.
    - **Bad behaviour**: Testers may skip old tests (that rarely find new bugs) and just write tests they know will find bugs to keep their numbers looking good.

### Test automation jeopardy

åœ¨æµ‹è¯•è‡ªåŠ¨åŒ–çš„èƒŒæ™¯ä¸‹,**jeopardy**(å±é™©ã€é£é™©)æŒ‡çš„æ˜¯æµ‹è¯•è‡ªåŠ¨åŒ–å¯èƒ½å¸¦æ¥çš„è´Ÿé¢å½±å“æˆ–é£é™©ã€‚

è™½ç„¶æµ‹è¯•è‡ªåŠ¨åŒ–æœ‰å¾ˆå¤šå¥½å¤„,ä½†å¦‚æœä½¿ç”¨ä¸å½“,ä¹Ÿå¯èƒ½ä¼šå¸¦æ¥ä¸€äº›é—®é¢˜,æ¯”å¦‚:

- ç»´æŠ¤è‡ªåŠ¨åŒ–æµ‹è¯•è„šæœ¬éœ€è¦é¢å¤–çš„æ—¶é—´å’Œæˆæœ¬
- è¿‡åº¦ä¾èµ–è‡ªåŠ¨åŒ–å¯èƒ½ä¼šå¿½ç•¥æ¢ç´¢æ€§æµ‹è¯•
- è‡ªåŠ¨åŒ–æµ‹è¯•å¯èƒ½äº§ç”Ÿè¯¯æŠ¥(false positives),æµªè´¹è°ƒæŸ¥æ—¶é—´
- åˆæœŸæŠ•å…¥å¤§,å¦‚æœé¡¹ç›®å˜åŒ–é¢‘ç¹,è‡ªåŠ¨åŒ–æµ‹è¯•å¯èƒ½éœ€è¦ç»å¸¸æ›´æ–°

å› æ­¤åœ¨å†³å®šæ˜¯å¦ä½¿ç”¨æµ‹è¯•è‡ªåŠ¨åŒ–æ—¶,éœ€è¦æƒè¡¡å…¶å¸¦æ¥çš„å¥½å¤„å’Œæ½œåœ¨çš„é£é™©ã€‚

ä¸ä¼šæ”¹å˜è¢«æµ‹è½¯ä»¶æ—¶åºæˆ–å…¶ä»–ç‰¹æ€§ï¼ˆtiming/characteristicsï¼‰çš„æµ‹è¯•ï¼Œé€šå¸¸æ›´é€‚åˆåšè‡ªåŠ¨åŒ–ã€‚

ä¾‹å­ï¼šAPI å›å½’ã€ç¡®å®šæ€§çš„ä¸šåŠ¡è§„åˆ™æ ¡éªŒã€æ•°æ®åº“çº¦æŸæ£€æŸ¥ã€æ¥å£è¿”å›ç /å­—æ®µæ ¡éªŒã€‚

ç»“æœæ›´å®¹æ˜“ç”±äººåˆ¤æ–­ï¼ˆæ¯”å¦‚è§†è§‰æ•ˆæœã€å¯ç”¨æ€§ä½“éªŒï¼‰ï¼Œæˆ–è€…å¾ˆå°‘è¿è¡Œçš„æµ‹è¯•ï¼Œé€šå¸¸æ›´é€‚åˆäººå·¥æµ‹è¯•ï¼ˆè‡ªåŠ¨åŒ–æ€§ä»·æ¯”ä½ï¼‰ã€‚

ä¾‹å­ï¼šUI å¤–è§‚æ˜¯å¦â€œçœ‹èµ·æ¥å¯¹â€ã€æ–‡æ¡ˆæ˜¯å¦è‡ªç„¶ã€äº¤äº’æ˜¯å¦é¡ºç•…ã€æ¢ç´¢æ€§æµ‹è¯•ã€ä¸€æ¬¡æ€§éªŒè¯ã€‚

### test automation tool

**Postman**Â is a tool for testing APIs. It helps automateÂ **integration and system-level**Â testing of RESTful APIs by allowing HTTP requests to be sent and responses to be checked. API tests can be grouped together and run sequentially, which is ideal for verifying that backend services return the correct data and response codes.

Postman offers several ways to automate testing. WithÂ **record and play**, API requests can be manually recorded and replayed later. For more advanced testing, JavaScript testÂ **scripts**Â can be written to check specific conditions. Postman also supportsÂ **data-driven**Â testing through the Collection Runner, which allows the same tests to be run with different sets of data to test various scenarios and edge cases.

### artificial intelligence in testing terms or abbreviations

- **False positive** is incorrect reporting: the code works well, but the test reports a bug.
- **Fitness function** is a measurement: it evaluates the test case performance by giving a numeric score. It can measure anything relevant like coverages, execution time, etc.
- **TCS (Test Case Selection)**: Selecting a subset of tests that finds the same or nearly the same number of errors as the entire test set.
- **TCP (Test Case Prioritization)**: Order test cases by likelihood of finding errors, so the most valuable tests are run first. The method does not reduce the number of tests, but running of tests can be interrupted, and still get reasonably good results.

**Broken authentication** means the system that checks your identityâ€”like login pages, passwords, and â€œstay logged inâ€ featuresâ€”does not protect you properly. When these parts of a system are weak, attackers may be able to log in as someone else without knowing their password. This can happen if the system allows very simple passwords, doesnâ€™t block repeated wrong attempts, has insecure password reset links, or lets old login sessions stay active for too long. In other words, the â€œlock on the doorâ€ exists, but it doesnâ€™t actually keep the wrong people out. Because of these weaknesses, attackers might access personal accounts, read private information, or even take over someoneâ€™s profile completely. 

To check if a system might suffer from broken authentication, We can try things like using an extremely weak password, seeing whether the account locks after many failed attempts, checking if logout actually ends the session, or observing whether password reset links expire quickly. If these protections donâ€™t work properly, the system may be vulnerable to attackers pretending to be legitimate users.

---

---

### 1. Definitions

**a) Acceptance testing**

Acceptance testing is a formal testing phase conducted to determine whether a system satisfies its acceptance criteria and to enable the customer or stakeholders to determine whether to accept the system. It is typically performed by end users or clients to validate that the software meets business requirements before deployment.

**b) Big Bang integration**

Big Bang integration is an integration testing approach where all components or modules are combined together at once and then tested as a whole. This method does not involve incremental integration and is typically used for small systems, though it makes defect localization difficult.

**c) Fuzz testing**

Fuzz testing (fuzzing) is a software testing technique that involves providing invalid, unexpected, or random data as inputs to a program to discover vulnerabilities, crashes, or bugs. It is particularly effective at finding security vulnerabilities and robustness issues.

**d) Glass box testing (white box testing)**

Glass box testing is a testing approach where the tester has full knowledge of the internal structure, design, and implementation of the system being tested. Test cases are designed based on code structure, logic paths, and internal workings to achieve structural coverage criteria.

**e) Negative testing**

Negative testing is a testing approach that focuses on verifying that the system handles invalid inputs, error conditions, and unexpected user behavior gracefully. It ensures the software does not crash or behave incorrectly when given invalid or unexpected data.

**f) Sowing/planting errors**

Sowing or planting errors is a technique where known defects are intentionally inserted into the software to evaluate the effectiveness of the testing process. The ratio of found planted errors to total planted errors can be used to estimate the number of real defects remaining in the system.


### Regression testingï¼ˆå›å½’æµ‹è¯•ï¼‰

- **æ˜¯ä»€ä¹ˆ**ï¼šåœ¨ä»£ç ä¿®æ”¹ï¼ˆä¿® bugã€åŠ åŠŸèƒ½ã€é‡æ„ã€å‡çº§ä¾èµ–ï¼‰ä¹‹åï¼Œå†è·‘ä¸€éå·²æœ‰æµ‹è¯•ï¼Œç¡®è®¤**åŸæ¥æ­£å¸¸çš„åŠŸèƒ½æ²¡æœ‰è¢«æ”¹å**ã€‚
- **ç›®çš„**ï¼šé˜²æ­¢â€œæ”¹ A å Bâ€çš„å‰¯ä½œç”¨ã€‚
- **ä¾‹å­**ï¼šè´­ç‰©ç½‘ç«™ä¿®å¤ä¼˜æƒ åˆ¸ bug åï¼Œå†æµ‹ä¸‹å•ã€æ”¯ä»˜ã€å‘ç¥¨ã€åº“å­˜æ‰£å‡ç­‰åŸæœ¬åŠŸèƒ½ã€‚
- **å¸¸è§å¯¹æ¯”**ï¼šå›å½’æµ‹è¯•ä¸ä¸€å®šæ˜¯â€œé‡æ–°æµ‹è¯•å…¨éƒ¨â€ï¼Œé€šå¸¸ä¼šåš**å›å½’æµ‹è¯•é›†é€‰æ‹©**ï¼ˆåªè·‘æœ€å…³é”®ã€æœ€å®¹æ˜“å—å½±å“çš„éƒ¨åˆ†ï¼‰ã€‚

### Reliability testingï¼ˆå¯é æ€§æµ‹è¯•ï¼‰

- **æ˜¯ä»€ä¹ˆ**ï¼šè¯„ä¼°ç³»ç»Ÿåœ¨è§„å®šæ¡ä»¶ä¸‹ã€è§„å®šæ—¶é—´å†…**ç¨³å®šè¿è¡Œã€ä¸å‡ºæ•…éšœ**çš„èƒ½åŠ›ã€‚
- **å…³æ³¨ç‚¹**ï¼šå´©æºƒç‡ã€é”™è¯¯ç‡ã€é•¿æ—¶é—´è¿è¡Œæ˜¯å¦å†…å­˜æ³„æ¼ã€æœåŠ¡æ˜¯å¦èƒ½æŒç»­æä¾›åŠŸèƒ½ã€‚
- **ä¾‹å­**ï¼šè®©æœåŠ¡å™¨è¿ç»­è¿è¡Œ 72 å°æ—¶å‹æµ‹ï¼Œçœ‹æ˜¯å¦å‡ºç°å´©æºƒæˆ–èµ„æºè€—å°½ã€‚
- **å¸¸è§å¯¹æ¯”**ï¼š
    - **æ€§èƒ½æµ‹è¯•**æ›´å…³æ³¨â€œå¿«ä¸å¿«â€ï¼Œ
    - **å¯é æ€§æµ‹è¯•**æ›´å…³æ³¨â€œç¨³ä¸ç¨³ã€ä¹…ä¸ä¹…â€ã€‚

### Requirement coverageï¼ˆéœ€æ±‚è¦†ç›–ç‡ / éœ€æ±‚è¦†ç›–ï¼‰

- **æ˜¯ä»€ä¹ˆ**ï¼šè¡¡é‡æµ‹è¯•æ˜¯å¦è¦†ç›–äº†éœ€æ±‚ã€‚é€šå¸¸æ˜¯â€œéœ€æ±‚ â†” æµ‹è¯•ç”¨ä¾‹â€çš„å¯è¿½è¸ªå…³ç³»ã€‚
- **æ€ä¹ˆç”¨**ï¼šæŠŠæ¯æ¡éœ€æ±‚ï¼ˆæˆ–ç”¨æˆ·æ•…äº‹ã€éªŒæ”¶æ ‡å‡†ï¼‰æ˜ å°„åˆ°è‡³å°‘ä¸€ä¸ªæµ‹è¯•ç”¨ä¾‹ï¼Œç»Ÿè®¡è¦†ç›–æƒ…å†µã€‚
- **ç›®çš„**ï¼šé¿å…åªæµ‹â€œå¼€å‘é¡ºæ‰‹æµ‹åˆ°çš„åœ°æ–¹â€ï¼Œè€Œæ¼æ‰å®¢æˆ·çœŸæ­£å…³å¿ƒçš„è¦æ±‚ã€‚
- **æ³¨æ„**ï¼šéœ€æ±‚è¦†ç›–é«˜ â‰  ç¼ºé™·å°‘ã€‚å®ƒåªè¯´æ˜â€œæµ‹åˆ°äº†â€ï¼Œä¸ä¿è¯â€œæµ‹å¾—å¥½â€ã€‚

### Unit testingï¼ˆå•å…ƒæµ‹è¯•ï¼‰

- **æ˜¯ä»€ä¹ˆ**ï¼šå¯¹æœ€å°å¯æµ‹è¯•å•å…ƒï¼ˆå‡½æ•°ã€æ–¹æ³•ã€ç±»ï¼‰è¿›è¡Œæµ‹è¯•ï¼Œé€šå¸¸ç”±å¼€å‘äººå‘˜å†™ï¼Œè·‘å¾—å¿«ï¼Œéš”ç¦»ä¾èµ–ï¼ˆmock/stubï¼‰ã€‚
- **ç›®çš„**ï¼šå°½æ—©å‘ç°é€»è¾‘é”™è¯¯ï¼Œå®šä½å¿«ã€‚
- **ä¾‹å­**ï¼šæµ‹è¯• `calculateTotal(cart)` åœ¨ä¸åŒè´­ç‰©è½¦è¾“å…¥ä¸‹è¿”å›å€¼æ˜¯å¦æ­£ç¡®ã€‚
- **ç‰¹ç‚¹**ï¼šç²’åº¦å°ã€æ•°é‡å¤šã€æ‰§è¡Œå¿«ã€‚

### Integration testingï¼ˆé›†æˆæµ‹è¯•ï¼‰

- **æ˜¯ä»€ä¹ˆ**ï¼šæµ‹è¯•å¤šä¸ªç»„ä»¶ç»„åˆåœ¨ä¸€èµ·æ—¶ï¼Œå®ƒä»¬çš„**æ¥å£ä¸äº¤äº’**æ˜¯å¦æ­£ç¡®ã€‚
- **ç›®çš„**ï¼šå‘ç°æ¨¡å—é—´å¥‘çº¦ï¼ˆAPI/æ•°æ®æ ¼å¼/è°ƒç”¨é¡ºåº/é”™è¯¯å¤„ç†ï¼‰çš„é—®é¢˜ã€‚
- **ä¾‹å­**ï¼šè®¢å•æœåŠ¡è°ƒç”¨åº“å­˜æœåŠ¡ã€æ”¯ä»˜æœåŠ¡ï¼Œæµ‹è¯•åœ¨åº“å­˜ä¸è¶³æˆ–æ”¯ä»˜å¤±è´¥æ—¶çš„æ•´ä½“è¡Œä¸ºã€‚
- **å¸¸è§å¯¹æ¯”**ï¼šå•å…ƒæµ‹è¯•ä¸ä¸€å®šä¼šæš´éœ²â€œæ¨¡å—ä¹‹é—´è¿èµ·æ¥åâ€çš„é—®é¢˜ã€‚

### System integrationï¼ˆç³»ç»Ÿé›†æˆ / ç³»ç»Ÿé›†æˆæµ‹è¯•ï¼Œå¸¸è§å†™æ³•æ˜¯ SITï¼‰

- **æ˜¯ä»€ä¹ˆ**ï¼šæŠŠâ€œç³»ç»Ÿâ€ä¸**å¤–éƒ¨ç³»ç»Ÿ/å­ç³»ç»Ÿ**é›†æˆèµ·æ¥æµ‹è¯•ï¼ˆä¾‹å¦‚ç¬¬ä¸‰æ–¹æ”¯ä»˜ã€èº«ä»½è®¤è¯ã€ç¡¬ä»¶è®¾å¤‡ã€å¤–éƒ¨æ•°æ®åº“ã€æ¶ˆæ¯é˜Ÿåˆ—ç­‰ï¼‰ã€‚
    - Integration testing æ›´åâ€œå†…éƒ¨æ¨¡å—ä¹‹é—´é›†æˆâ€ï¼Œ
    - System integration æ›´åâ€œç³»ç»Ÿä¸ç³»ç»Ÿä¹‹é—´é›†æˆâ€ï¼ˆèŒƒå›´æ›´å¤§ã€ç¯å¢ƒæ›´åƒçœŸå®ï¼‰ã€‚
- **ç›®çš„**ï¼šéªŒè¯è·¨ç³»ç»Ÿçš„ç«¯åˆ°ç«¯æµç¨‹ã€åè®®ã€ç½‘ç»œã€æƒé™ã€ç¯å¢ƒé…ç½®ç­‰ã€‚
- **ä¾‹å­**ï¼šä½ çš„ç³»ç»Ÿä¸é“¶è¡Œæ”¯ä»˜ç½‘å…³ã€ç‰©æµæ¥å£ã€å­¦æ ¡ SSO ç™»å½•é›†æˆåçš„å…¨é“¾è·¯æµ‹è¯•ã€‚

### Acceptance testingï¼ˆéªŒæ”¶æµ‹è¯•ï¼‰

- **æ˜¯ä»€ä¹ˆ**ï¼šç”±å®¢æˆ·ã€ä¸šåŠ¡ä»£è¡¨æˆ–æœ€ç»ˆç”¨æˆ·ï¼ˆæˆ–ä»£è¡¨ï¼‰è¿›è¡Œï¼Œåˆ¤æ–­ç³»ç»Ÿæ˜¯å¦æ»¡è¶³**éªŒæ”¶æ ‡å‡†/ä¸šåŠ¡ç›®æ ‡**ï¼Œå†³å®šæ˜¯å¦æ¥å—äº¤ä»˜ã€‚
- **ç›®çš„**ï¼šéªŒè¯â€œåšçš„æ˜¯ä¸æ˜¯å®¢æˆ·è¦çš„â€ï¼ˆåéªŒè¯/ç¡®è®¤ä¸šåŠ¡ä»·å€¼ï¼‰ã€‚
- **ä¾‹å­**ï¼šå®¢æˆ·æŒ‰éªŒæ”¶æ¸…å•æ“ä½œï¼šæ³¨å†Œã€ä¸‹å•ã€é€€æ¬¾ã€æƒé™ç®¡ç†ç­‰éƒ½ç¬¦åˆåˆåŒ/éœ€æ±‚ã€‚
- **å¸¸è§ç±»å‹**ï¼šUATï¼ˆç”¨æˆ·éªŒæ”¶æµ‹è¯•ï¼‰å¸¸è¢«è§†ä¸º acceptance testing çš„ä¸€ç§å®è·µå½¢å¼ã€‚

### Confusion matrixï¼ˆæ··æ·†çŸ©é˜µï¼šTP / FP / TN / FNï¼‰

ç”¨äº**äºŒåˆ†ç±»**ï¼ˆæˆ–æ¨å¹¿åˆ°å¤šåˆ†ç±»ï¼‰çš„é¢„æµ‹/åˆ¤å®šç»“æœç»Ÿè®¡è¡¨ã€‚å…ˆå®šä¹‰ï¼š

- **Positive / Negative**ï¼šä¾‹å¦‚â€œæœ‰ç¼ºé™·â€ä¸ºæ­£ç±»ï¼Œâ€œæ— ç¼ºé™·â€ä¸ºè´Ÿç±»ã€‚
- **TPï¼ˆTrue Positiveï¼‰çœŸé˜³æ€§**ï¼šå®é™…æ˜¯æ­£ç±»ï¼Œä½ ä¹Ÿåˆ¤æˆæ­£ç±»ï¼ˆåˆ¤å¯¹äº†ï¼‰ã€‚
- **FPï¼ˆFalse Positiveï¼‰å‡é˜³æ€§**ï¼šå®é™…æ˜¯è´Ÿç±»ï¼Œä½ å´åˆ¤æˆæ­£ç±»ï¼ˆè¯¯æŠ¥ï¼‰ã€‚
- **TNï¼ˆTrue Negativeï¼‰çœŸé˜´æ€§**ï¼šå®é™…æ˜¯è´Ÿç±»ï¼Œä½ ä¹Ÿåˆ¤æˆè´Ÿç±»ï¼ˆåˆ¤å¯¹äº†ï¼‰ã€‚
- **FNï¼ˆFalse Negativeï¼‰å‡é˜´æ€§**ï¼šå®é™…æ˜¯æ­£ç±»ï¼Œä½ å´åˆ¤æˆè´Ÿç±»ï¼ˆæ¼æŠ¥ï¼‰ã€‚

åœ¨æµ‹è¯•è¯­å¢ƒé‡Œï¼š

- **FP**ï¼šç³»ç»Ÿå…¶å®æ²¡é—®é¢˜ï¼Œä½ æŠ¥äº† bugï¼ˆè¯¯æŠ¥ï¼‰ã€‚
- **FN**ï¼šç³»ç»Ÿæœ‰é—®é¢˜ï¼Œä½ æ²¡æµ‹å‡ºæ¥ï¼ˆæ¼æŠ¥ï¼Œé€šå¸¸æ›´å±é™©ï¼‰ã€‚

### Compute metricsï¼ˆç”±æ··æ·†çŸ©é˜µè®¡ç®—æŒ‡æ ‡ï¼šaccuracyã€precisionã€recall ç­‰ï¼‰

å¸¸ç”¨æŒ‡æ ‡ï¼ˆä»¥äºŒåˆ†ç±»ä¸ºä¾‹ï¼‰ï¼š

- **Accuracyï¼ˆå‡†ç¡®ç‡ï¼‰**ï¼šæ•´ä½“åˆ¤å¯¹çš„æ¯”ä¾‹
    - å…¬å¼ï¼š$(TP + TN) / (TP + FP + TN + FN)$
    - é€‚ç”¨ï¼šç±»åˆ«åˆ†å¸ƒæ¯”è¾ƒå‡è¡¡æ—¶æ›´æœ‰æ„ä¹‰ã€‚
    - é™·é˜±ï¼šä¸¥é‡ç±»åˆ«ä¸å¹³è¡¡æ—¶ä¼šâ€œçœ‹èµ·æ¥å¾ˆé«˜ä½†æ²¡ç”¨â€ã€‚
- **Precisionï¼ˆç²¾ç¡®ç‡ / æŸ¥å‡†ç‡ï¼‰**ï¼šä½ åˆ¤ä¸ºæ­£çš„é‡Œé¢ï¼Œæœ‰å¤šå°‘æ˜¯çœŸçš„æ­£
    - å…¬å¼ï¼š$TP / (TP + FP)$
    - é«˜ precision è¡¨ç¤ºï¼š**è¯¯æŠ¥å°‘**ã€‚
- **Recallï¼ˆå¬å›ç‡ / æŸ¥å…¨ç‡ / TPRï¼‰**ï¼šå®é™…ä¸ºæ­£çš„é‡Œé¢ï¼Œä½ æ‰¾å›äº†å¤šå°‘
    - å…¬å¼ï¼š$TP / (TP + FN)$
    - é«˜ recall è¡¨ç¤ºï¼š**æ¼æŠ¥å°‘**ã€‚
- **F1-score**ï¼šprecision å’Œ recall çš„æŠ˜ä¸­ï¼ˆè°ƒå’Œå¹³å‡ï¼‰**ï¼ˆharmonic meanï¼‰**
    - å…¬å¼ï¼š$2PR/(P+R)$
    - ç”¨äºéœ€è¦å¹³è¡¡è¯¯æŠ¥å’Œæ¼æŠ¥çš„åœºæ™¯ã€‚
        - å¦‚æœ **P=1, R=0**ï¼š(F1 = 0)ï¼ˆä¸€ä¸ªä¸º 0ï¼Œæ•´ä½“å°± 0ï¼‰
        - å¦‚æœ **P=0.9, R=0.1**ï¼š(F1 approx 0.18)ï¼ˆå·®çš„é‚£ä¸ªä¼šå¼ºçƒˆæ‹–åè…¿ï¼‰
        - å¦‚æœ **P=0.5, R=0.5**ï¼š(F1=0.5)
        
        æ‰€ä»¥å®ƒå¼ºè°ƒçš„æ˜¯**å¹³è¡¡**ï¼Œé€‚åˆâ€œè¯¯æŠ¥ï¼ˆFPï¼‰å’Œæ¼æŠ¥ï¼ˆFNï¼‰éƒ½å¾ˆé‡è¦â€çš„åœºæ™¯ã€‚
